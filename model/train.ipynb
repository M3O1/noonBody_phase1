{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from model import get_1000fps_model\n",
    "from data import dataGenerator, load_dataset\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from keras import backend\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_contour_mask(mask):\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    erosion = cv2.erode(mask, kernel, iterations =1)\n",
    "    return mask - erosion\n",
    "\n",
    "def save_test_images(pred,images):\n",
    "    pred = (pred < 0.5).astype(np.uint8)\n",
    "    \n",
    "    results = []\n",
    "    for i in range(pred.shape[0]):\n",
    "        mask = extract_contour_mask(pred[i])\n",
    "        mask = np.stack([mask*255,mask*0,mask*0],axis=-1)\n",
    "        mask = cv2.resize(mask,(256,256))\n",
    "        results.append(cv2.add(images[i],mask))\n",
    "    results = np.concatenate(results)\n",
    "    \n",
    "    results = cv2.cvtColor(results,cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(os.path.join(model_dir,\"example_output.png\"),results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set-up \n",
    "input_size = (96,96)\n",
    "example_dir = \"../example/\"\n",
    "model_dir = os.path.join(\"../save/\",datetime.now().strftime(\"basic-%m%d-%H%M\"))\n",
    "os.makedirs(model_dir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load example images\n",
    "images = []\n",
    "inputs = []\n",
    "for filename in os.listdir(example_dir):\n",
    "    ex_path = os.path.join(example_dir,filename)\n",
    "    image = cv2.imread(ex_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    input_ = cv2.resize(image,input_size)\n",
    "    input_ = input_/255.\n",
    "    image = cv2.resize(image,(256,256))\n",
    "    inputs.append(input_)\n",
    "    images.append(image)\n",
    "\n",
    "inputs = np.stack(inputs,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data generator\n",
    "batch_size = 64\n",
    "\n",
    "dataset = load_dataset(input_size=input_size)\n",
    "trainset, testset = train_test_split(dataset,test_size=0.1)\n",
    "\n",
    "train_nums = len(trainset)\n",
    "train_steps = train_nums // batch_size\n",
    "\n",
    "test_nums = len(testset)\n",
    "test_steps = test_nums // batch_size\n",
    "\n",
    "traingen = dataGenerator(trainset, input_size, batch_size)\n",
    "testgen = dataGenerator(testset, input_size, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set-up model\n",
    "model = get_1000fps_model(input_size)\n",
    "model.compile(\"adam\",\n",
    "              loss=\"mse\",\n",
    "             metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit_generator(traingen,\n",
    "                           train_steps,\n",
    "                           epochs=50,\n",
    "                           verbose=0, \n",
    "                           validation_data = testgen,\n",
    "                           validation_steps = test_steps,\n",
    "                           callbacks=[TQDMNotebookCallback()])\n",
    "\n",
    "pred = model.predict_on_batch(inputs)\n",
    "save_test_images(pred,images)\n",
    "\n",
    "# Draw the results\n",
    "train_mse = hist.history['mean_squared_error']\n",
    "valid_mse = hist.history['val_mean_squared_error']\n",
    "df = pd.DataFrame({\"mse-train\":train_mse,\"mse-valid\":valid_mse})\n",
    "df.plot().figure.savefig(os.path.join(model_dir,\"training.png\"))\n",
    "    \n",
    "# Save Model\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(os.path.join(model_dir,\"model.json\"), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(os.path.join(model_dir,\"model.h5\"))\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
